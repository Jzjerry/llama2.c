{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/silver/workbench/tvm-unity\n"
     ]
    }
   ],
   "source": [
    "!echo ${TVM_HOME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.dev0\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relay, relax\n",
    "print(tvm.__version__)\n",
    "import numpy as np\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tiny llamas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (tok_embeddings): Embedding(32000, 288)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x TransformerBlock(\n",
       "      (attention): Attention(\n",
       "        (wq): Linear(in_features=288, out_features=288, bias=False)\n",
       "        (wk): Linear(in_features=288, out_features=288, bias=False)\n",
       "        (wv): Linear(in_features=288, out_features=288, bias=False)\n",
       "        (wo): Linear(in_features=288, out_features=288, bias=False)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): Linear(in_features=288, out_features=768, bias=False)\n",
       "        (w2): Linear(in_features=768, out_features=288, bias=False)\n",
       "        (w3): Linear(in_features=288, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): Linear(in_features=288, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import *\n",
    "device = \"cpu\"\n",
    "ckpt_path = \"tinyllamas/stories15M.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "checkpoint_model_args = checkpoint[\"model_args\"]\n",
    "\n",
    "model_args = dict()\n",
    "\n",
    "for k in [\"dim\", \"n_layers\", \"n_heads\", \"n_kv_heads\", \"vocab_size\", \"multiple_of\", \"max_seq_len\"]:\n",
    "    model_args[k] = checkpoint_model_args[k]\n",
    "# create the model\n",
    "gptconf = ModelArgs(**model_args)\n",
    "model = Transformer(gptconf)\n",
    "state_dict = checkpoint[\"model\"]\n",
    "# fix the keys of the state dictionary :(\n",
    "# honestly no idea how checkpoints sometimes get this prefix, have to debug more\n",
    "unwanted_prefix = \"_orig_mod.\"\n",
    "for k, v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix) :]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict)\n",
    "iter_num = checkpoint[\"iter_num\"]\n",
    "best_val_loss = checkpoint[\"best_val_loss\"]\n",
    "model.to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1, 23052,   338,   263,  2217,  8023]])\n"
     ]
    }
   ],
   "source": [
    "from tokenizer import Tokenizer\n",
    "\n",
    "vocab_size = gptconf.vocab_size\n",
    "tokenizer_model = \"tokenizer.model\"\n",
    "enc = Tokenizer(tokenizer_model=tokenizer_model)\n",
    "\n",
    "start = \"Jerry is a little boy\"\n",
    "\n",
    "start_ids = enc.encode(start, bos=True, eos=False)\n",
    "input_data = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "print(input_data)\n",
    "# scripted_model = torch.jit.trace(model, input_data).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import to Relay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/silver/workbench/llama2.c/tvm.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/silver/workbench/llama2.c/tvm.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtvm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrelax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfrontend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m from_fx\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/silver/workbench/llama2.c/tvm.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m fx\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/silver/workbench/llama2.c/tvm.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m symbolic_model \u001b[39m=\u001b[39m fx\u001b[39m.\u001b[39;49msymbolic_trace(model)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/silver/workbench/llama2.c/tvm.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m mod, params \u001b[39m=\u001b[39m from_fx(symbolic_model, shape_list)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/silver/workbench/llama2.c/tvm.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# TODO: Fuck, no way to convert it! TVM has no support for it.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:1109\u001b[0m, in \u001b[0;36msymbolic_trace\u001b[0;34m(root, concrete_args)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[39mSymbolic tracing API\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m    GraphModule: a Module created from the recorded operations from ``root``.\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m tracer \u001b[39m=\u001b[39m Tracer()\n\u001b[0;32m-> 1109\u001b[0m graph \u001b[39m=\u001b[39m tracer\u001b[39m.\u001b[39;49mtrace(root, concrete_args)\n\u001b[1;32m   1110\u001b[0m name \u001b[39m=\u001b[39m (\n\u001b[1;32m   1111\u001b[0m     root\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(root, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule) \u001b[39melse\u001b[39;00m root\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m   1112\u001b[0m )\n\u001b[1;32m   1113\u001b[0m \u001b[39mreturn\u001b[39;00m GraphModule(tracer\u001b[39m.\u001b[39mroot, graph, name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:778\u001b[0m, in \u001b[0;36mTracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autowrap_search:\n\u001b[1;32m    772\u001b[0m             _autowrap_check(\n\u001b[1;32m    773\u001b[0m                 patcher, module\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autowrap_function_ids\n\u001b[1;32m    774\u001b[0m             )\n\u001b[1;32m    775\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_node(\n\u001b[1;32m    776\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    777\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m--> 778\u001b[0m             (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_arg(fn(\u001b[39m*\u001b[39;49margs)),),\n\u001b[1;32m    779\u001b[0m             {},\n\u001b[1;32m    780\u001b[0m             type_expr\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__annotations__\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    781\u001b[0m         )\n\u001b[1;32m    783\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubmodule_paths \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/workbench/llama2.c/model.py:253\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, tokens, targets)\u001b[0m\n\u001b[1;32m    251\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtok_embeddings(tokens)\n\u001b[1;32m    252\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(h)\n\u001b[0;32m--> 253\u001b[0m freqs_cos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfreqs_cos[:seqlen]\n\u001b[1;32m    254\u001b[0m freqs_sin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfreqs_sin[:seqlen]\n\u001b[1;32m    256\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "input_name = \"input0\"\n",
    "shape_list = [(input_name, input_data.shape)]\n",
    "\n",
    "\n",
    "# Relay\n",
    "# mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
    "\n",
    "# Relax\n",
    "from tvm.relax.frontend.torch import from_fx\n",
    "from torch import fx\n",
    "\n",
    "symbolic_model = fx.symbolic_trace(model)\n",
    "\n",
    "mod, params = from_fx(symbolic_model, shape_list)\n",
    "\n",
    "\n",
    "# TODO: Fuck, no way to convert it! TVM has no support for it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
