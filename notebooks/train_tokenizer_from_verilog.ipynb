{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 端到端示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'module', '▁', 'V', 'ex', 'r', 'isc', 'v']\n",
      "[4, 481, 4, 501, 23, 510, 438, 421]\n",
      "module Vexriscv\n",
      "module Vexriscv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=VexRiscv.v --model_prefix=verilog --vocab_size=512\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: VexRiscv.v\n",
      "  input_format: \n",
      "  model_prefix: verilog\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 512\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: VexRiscv.v\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 3358 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=198651\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9597% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=81\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999597\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 3358 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=113225\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 2230 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 3358\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 3526\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 3526 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1216 obj=45.7826 num_tokens=60077 num_tokens/piece=49.4054\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1037 obj=37.3845 num_tokens=60118 num_tokens/piece=57.973\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=777 obj=37.7057 num_tokens=60381 num_tokens/piece=77.7104\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=777 obj=37.415 num_tokens=60382 num_tokens/piece=77.7117\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=582 obj=38.1381 num_tokens=61250 num_tokens/piece=105.241\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=582 obj=37.9595 num_tokens=61323 num_tokens/piece=105.366\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=563 obj=38.0111 num_tokens=61559 num_tokens/piece=109.341\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=563 obj=37.9838 num_tokens=61559 num_tokens/piece=109.341\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: verilog.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: verilog.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# 用红楼梦.txt训练一个sentencepiece模型，模型前缀model_prefix=meng, 会生成meng.model, meng.vocab.\n",
    "# meng.vocab仅仅是一个参考，在分词中并未使用。\n",
    "spm.SentencePieceTrainer.train('--input=VexRiscv.v --model_prefix=verilog --vocab_size=512')\n",
    "\n",
    "# 实例化一个分词实例，然后加载训练好的meng.model\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('verilog.model')\n",
    "\n",
    "# encode: text => id\n",
    "print(sp.encode_as_pieces('module Vexriscv'))\n",
    "print(sp.encode_as_ids('module Vexriscv'))\n",
    "\n",
    "# decode: id => text\n",
    "print(sp.decode_pieces(['▁', 'module', '▁', 'V', 'ex', 'r', 'isc', 'v']))\n",
    "print(sp.decode_ids([4, 481, 4, 501, 23, 510, 438, 421]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词表大小=512\n",
      "[4, 77]\n",
      "reg\n",
      "77\n",
      "0\n",
      "<unk> False\n",
      "<s> True\n",
      "</s> True\n"
     ]
    }
   ],
   "source": [
    "# 返回 vocab size\n",
    "print(f\"词表大小={sp.get_piece_size()}\")\n",
    "\n",
    "print(sp.encode_as_ids(\"reg\"))\n",
    "# id <=> piece conversion\n",
    "print(sp.id_to_piece(77))\n",
    "print(sp.piece_to_id('reg'))\n",
    "\n",
    "# id=0的位置留着给UNK token, 可对其进行修改\n",
    "print(sp.piece_to_id('__MUST_BE_UNKNOWN__'))\n",
    "\n",
    "# 控制符 unk, <s>, </s> 默认id对应（0,1,2）\n",
    "for id in range(3):\n",
    "      print(sp.id_to_piece(id), sp.is_control(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SentencePiece model from ../tokenizer.model\n",
      "#words: 32000 - BOS ID: 1 - EOS ID: 2 - PAD ID: -1 - UNK ID : 0\n",
      "Loaded SentencePiece model from verilog.model\n",
      "#words: 512 - BOS ID: 1 - EOS ID: 2 - PAD ID: -1 - UNK ID : 0\n"
     ]
    }
   ],
   "source": [
    "# 加载一个社区训练好的tokenizer对比下。\n",
    "\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "model_path = \"../tokenizer.model\"\n",
    "sp_model = SentencePieceProcessor(model_file=model_path)\n",
    "print(f\"Loaded SentencePiece model from {model_path}\")\n",
    "\n",
    "# BOS / EOS token IDs\n",
    "n_words: int = sp_model.vocab_size()\n",
    "bos_id: int = sp_model.bos_id()\n",
    "eos_id: int = sp_model.eos_id()\n",
    "pad_id: int = sp_model.pad_id()\n",
    "unk_id: int = sp_model.unk_id()\n",
    "print(f\"#words: {n_words} - BOS ID: {bos_id} - EOS ID: {eos_id} - PAD ID: {pad_id} - UNK ID : {unk_id}\")\n",
    "\n",
    "\n",
    "model_path = \"verilog.model\"\n",
    "sp_model = SentencePieceProcessor(model_file=model_path)\n",
    "print(f\"Loaded SentencePiece model from {model_path}\")\n",
    "\n",
    "# BOS / EOS token IDs\n",
    "n_words: int = sp_model.vocab_size()\n",
    "bos_id: int = sp_model.bos_id()\n",
    "eos_id: int = sp_model.eos_id()\n",
    "pad_id: int = sp_model.pad_id()\n",
    "print(f\"#words: {n_words} - BOS ID: {bos_id} - EOS ID: {eos_id} - PAD ID: {pad_id} - UNK ID : {unk_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPE (Byte pair encoding) model\n",
    "\n",
    "可通过 -model_type=bpe 指定model类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** BPE ***\n",
      "['▁assign', '▁ptr', 'D', 'if', '▁=', '▁(', 'pushPtr', '_', 'value', '▁', '-', '▁popPtr', '_', 'value', ');']\n",
      "[]\n",
      "['▁assign', '▁ptr', 'D', 'if', '▁=', '▁(', 'pushPtr', '_', 'value', '▁', '-', '▁popPtr', '_', 'value', ');']\n",
      "[61, 898, 973, 109, 19, 77, 464, 943, 324, 945, 0, 563, 943, 324, 91]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=VexRiscv.v --model_prefix=verilog --vocab_size=1024 --model_type=bpe\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: VexRiscv.v\n",
      "  input_format: \n",
      "  model_prefix: verilog\n",
      "  model_type: BPE\n",
      "  vocab_size: 1024\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: VexRiscv.v\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 3358 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=198651\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9597% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=81\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999597\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 3358 sentences.\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 3358\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 3526\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4029 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1385 size=20 all=1041 active=959 piece=ory\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=897 size=40 all=1112 active=1030 piece=lePlugin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=757 size=60 all=1160 active=1078 piece=stage\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=433 size=80 all=1253 active=1171 piece=accumul\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=352 size=100 all=1338 active=1256 piece=um\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=347 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=304 size=120 all=1381 active=1041 piece=to\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=237 size=140 all=1427 active=1087 piece=AL\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=191 size=160 all=1483 active=1143 piece=ration\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=157 size=180 all=1599 active=1259 piece=▁1'\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=133 size=200 all=1612 active=1272 piece=input\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=132 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=128 size=220 all=1653 active=1041 piece=Denominator\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=111 size=240 all=1714 active=1102 piece=Num\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=97 size=260 all=1731 active=1119 piece=rspJoin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=89 size=280 all=1783 active=1171 piece=RE\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=79 size=300 all=1847 active=1235 piece=sh\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=79 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=320 all=1874 active=1024 piece=va\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=340 all=1927 active=1077 piece=ault\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=360 all=1953 active=1103 piece=pus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=380 all=2037 active=1187 piece=rite\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=400 all=2057 active=1207 piece=▁Branch\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=46 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=420 all=2071 active=1014 piece=Full\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=440 all=2104 active=1047 piece=AB\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=460 all=2174 active=1117 piece=▁({\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=480 all=2227 active=1170 piece=1}\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=500 all=2291 active=1234 piece=_7_\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=28 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=520 all=2304 active=1014 piece=addSub\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=540 all=2397 active=1107 piece=Overflow\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=560 all=2435 active=1145 piece=▁local\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=580 all=2497 active=1207 piece=0)\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=600 all=2533 active=1243 piece=RegFile\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=620 all=2562 active=1028 piece=Co\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=640 all=2630 active=1096 piece=DO\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=660 all=2641 active=1107 piece=(|\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=680 all=2677 active=1143 piece=▁5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=700 all=2747 active=1213 piece=!=\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=720 all=2808 active=1061 piece=Lo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=740 all=2876 active=1129 piece=readed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=760 all=2913 active=1166 piece=inc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=780 all=2931 active=1184 piece=ADDRESS\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=800 all=2923 active=1176 piece=4)\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=820 all=2970 active=1040 piece=reset\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=840 all=3022 active=1092 piece=ace\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=860 all=3039 active=1109 piece=jumpInterface\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=880 all=3094 active=1164 piece=Mov\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=900 all=3103 active=1173 piece=0000001\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=920 all=3120 active=1014 piece=3);\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=940 all=3149 active=1043 piece=[30]\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: verilog.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: verilog.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "spm.SentencePieceTrainer.train('--input=VexRiscv.v --model_prefix=verilog --vocab_size=1024 --model_type=bpe')\n",
    "sp_bpe = spm.SentencePieceProcessor()\n",
    "sp_bpe.load('verilog.model')\n",
    "\n",
    "print('*** BPE ***')\n",
    "print(sp_bpe.encode_as_pieces('assign ptrDif = (pushPtr_value - popPtr_value);'))\n",
    "print(sp_bpe.nbest_encode_as_pieces('assign ptrDif = (pushPtr_value - popPtr_value);', 5))  # returns an empty list.\n",
    "\n",
    "# encode: text => id\n",
    "print(sp_bpe.encode_as_pieces('assign ptrDif = (pushPtr_value - popPtr_value);'))\n",
    "print(sp_bpe.encode_as_ids('assign ptrDif = (pushPtr_value - popPtr_value);'))\n",
    "\n",
    "# decode: id => text\n",
    "# print(sp_bpe.decode_pieces())\n",
    "# print(sp_bpe.decode_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
